{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Causal Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why Study Causal Inference? \n",
    "- What are some mistakes that could happen if we do a naive analysis?\n",
    "  - Confounding example\n",
    "  - The definition of the do-operator\n",
    "\n",
    "RCTs\n",
    "    To find causal effects, one could randomize the treatment assignment. \n",
    "\n",
    "Chain\n",
    "\n",
    "Fork\n",
    "\n",
    "Collider\n",
    "\n",
    "Descendant of a collider\n",
    "\n",
    "Backdoor Criterion - \n",
    "  - When is seeing = doing?\n",
    "  - assumes you know the structure of the problem well enough\n",
    "  \n",
    "do-calculus\n",
    "\n",
    "Adjustment Formula\n",
    "  - derivation\n",
    "  \n",
    "Frontdoor Criterion\n",
    "  - lets us deal with partial knowledge of the graph / unmeasured variables\n",
    "  \n",
    "Crazy example\n",
    "\n",
    "Transportability\n",
    "\n",
    "Resources\n",
    "\n",
    "Book Club"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Causality is Ubiquitous\n",
    "\n",
    "A lot of interesting questions are **causal** questions.\n",
    "\n",
    "Epidemiology: I heard vaping is killing people. A friend of mine vapes. Should he switch back to smoking?\n",
    "\n",
    "Economics: What would happen to our economy if we increase taxes?\n",
    "\n",
    "Software Engineering: What code is *slowing down* our application?\n",
    "\n",
    "Marketing: What changes on our website would increase visits of Marketing Qualified Leads?\n",
    "\n",
    "Education: What interventions are *increasing* graduation rates of high school students?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothetical Scenario\n",
    "\n",
    "We want to improve students' graduation rates. Let's say we have some treatment T and we're trying to analyze the efficacy of treatment T. We find that on average, the graduation rates of those who get treatment T are 31 percentage points *worse* than those who didn't get treatment T. In other words,\n",
    "\\begin{equation}\n",
    "\\begin{aligned}\n",
    "    P(G=1 \\mid T=1) - P(G=0 \\mid T=0) \\approx -31\\%\n",
    "\\end{aligned}\n",
    "\\end{equation}\n",
    "\n",
    "### Question:\n",
    "Should we recommend treatment T to students?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer:\n",
    "\n",
    "It depends on the data-generating mechanism!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation Does Not Necessarily Imply Causation\n",
    "Here's an example where looking at associations naively leads to the wrong conclusion. \n",
    "\n",
    "Below is an example where treatment is negatively associated with graduation rate, even though the treatment is actually beneficial, on average!\n",
    "\n",
    "How could that be? Let's say in a hypothetical world, there are only three variables that matter: treatment $T$, graduation rate $G$. Students classified as \"at-risk\" $R$ are more likely to be sent to receive tutoring. At-risk students by definition are less likely to graduate. In other words, $R$ is a common cause of $T$ and $G$. Another way to say that is $T$ and $G$ are **confounded** by $R$. So if there's a lot of people at-risk who receive treatment, then it is quite possible that there is a negative association between the treatment and outcome, *even though the treatment actually improves the outcomes for most/all individuals*.\n",
    "\n",
    "| Risk confounds Tutoring and Graduate |\n",
    "| - |\n",
    "![Risk is a common cause of treatment and graduation](./img/risk-tutoring-graduate.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confounding Example Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def risk(sample_size=10000):\n",
    "    \"\"\"\n",
    "      We generate two types of people: At-risk vs. Not at-risk. \n",
    "      Risk, for example, could be in relation to dropping out of high school.\n",
    "    \"\"\"\n",
    "    \n",
    "    return np.random.binomial(n=1, p=0.3, size=sample_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tutoring(riskiness, proba_tutor_given_not_risky=0.1, proba_tutor_given_risky=0.9):\n",
    "    \"\"\"\n",
    "        Non-risky people (riskiness == 0) have a 10% chance of receiving a tutoring.\n",
    "        However, risky people have a 90% chance of receiving the tutoring.\n",
    "    \"\"\"\n",
    "    \n",
    "    probability_of_receiving_tutoring = \\\n",
    "        (riskiness == 0) * proba_tutor_given_not_risky + \\\n",
    "        (riskiness == 1) * proba_tutor_given_risky\n",
    "    \n",
    "    return np.random.binomial(n=1, p=probability_of_receiving_tutoring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graduate(riskiness, tutored):\n",
    "    \"\"\"\n",
    "        Tutoring increases graduation rates by 10 percentage points.\n",
    "        \n",
    "        If risky and tutoring, graduation rate = 0.3\n",
    "        If risky and not tutoring, graduation rate = 0.2\n",
    "        If not-risky and tutoring, graduation rate = 0.9\n",
    "        If not-risky and not tutoring, graduation rate = 0.8\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    risky_and_tutored_grad_rate = 0.3\n",
    "    risky_and_not_tutored_grad_rate = 0.2\n",
    "    not_risky_and_tutored_grad_rate = 0.9\n",
    "    not_risky_and_not_tutored_grad_rate = 0.85\n",
    "    \n",
    "    graduation_probas = (riskiness == 1) * (tutored == 1) * risky_and_tutored_grad_rate + \\\n",
    "        (riskiness == 1) * (tutored == 0) * risky_and_not_tutored_grad_rate + \\\n",
    "        (riskiness == 0) * (tutored == 1) * not_risky_and_tutored_grad_rate + \\\n",
    "        (riskiness == 0) * (tutored == 0) * not_risky_and_not_tutored_grad_rate\n",
    "    \n",
    "    return np.random.binomial(n=1, p=graduation_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "riskiness = risk(sample_size)\n",
    "tutored = drug(riskiness)\n",
    "graduated = graduate(riskiness, tutored)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    'risk': riskiness,\n",
    "    'tutored': tutored,\n",
    "    'graduated': graduated\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Associated Risk Difference: $P(G=1 \\mid T=1) - P(G=0 \\mid T=0) \\approx -31\\%$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.31"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(\n",
    "    df[df['tutored'] == 1].graduated.mean() - df[df['tutored'] == 0].graduated.mean(),\n",
    "    2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, if we do a randomized control trial (i.e. we randomize the assignment of the treatment), we see that the treatment actually improves the outcomes by 6%, on average!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We generate a population with roughly the same percentage of at-risk kids\n",
    "treated_sample = risk(sample_size)\n",
    "untreated_sample = risk(sample_size)\n",
    "\n",
    "round(\n",
    "    graduate(treated_sample, tutored=1).mean() - graduate(untreated_sample, tutored=0).mean(),\n",
    "    2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Causal Risk Difference: RCT of graduation rates given treated minus graduation rates given untreated = $6\\%$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we were to only look at the associated risk difference (i.e. make a comparison of graduation rates of those who got treated vs. those who didn't get treated), we would erroneously conclude that the treatment, on average, is bad (i.e. decreases graduation rate by 31%), **but in actuality, it boosts graduation rate, on average, by 6 percentage points!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The meaning of the *do*-operator\n",
    "\n",
    "Now we introduce the $do$-notation. $do(T=t)$ means we force the variable $T$ for the population of interest to be set to $t$ in an idealized way. When we $do(T=t)$, $T$ stops listening to other variables (i.e. becomes *exogenous*) and is set to $t$. \n",
    "\n",
    "Graphically, we can represent $do(T=t)$ as removing the arrow from $R$ to $T$:\n",
    "\n",
    "| $do(T=t)$ removes arrow from R to T |\n",
    "|-|\n",
    "| ![Graph like above, but R no longer has an arrow to T](./img/rct-tutoring-graduate.png) |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Randomized Control Trials (A/B Testing)\n",
    "\n",
    "One way to compute the average causal effect in the example above is to get two random samples of the treatment, assign one of them to the treatment, and then not assign the other. We could then subtract the means of each group. In our example above, the causal risk difference, a measure of causal effect, is computed as follows:\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{aligned}\n",
    "    \\text{CRD} &= P(G=1 \\mid do(T=1)) - P(G=1 \\mid do(T=0))\n",
    "\\end{aligned}\n",
    "\\end{equation}\n",
    "\n",
    "As we can see from above, the results of $P(G=1 \\mid do(T=t))$ can be different from $P(G=1 \\mid T=t)$, which is just another way of saying that correlation (positive, zero, or negative) does not necessarily imply causation.\n",
    "\n",
    "\n",
    "### Pros:\n",
    "- Removes confounding on treatment. *Nice especially when there are a lot of confounding variables*.\n",
    "- Assuming that all the people in the beginning of the study are still available at the end of the study (i.e. no selection bias), the only thing that's different between the treatment group and the control group is the presence or lack of treatment. Therefore, the difference in outcomes between the two could be attributed to the treatment!\n",
    "- Good [*internal validity*](https://en.wikipedia.org/wiki/Internal_validity).\n",
    "- Results are generally easy to understand, easy to interpret.\n",
    "\n",
    "Fig 1: Treatment Group in RCT (one square = 100k of that animal), assuming no selection bias. Dog='At Risk', Cat='Not At Risk'\n",
    "\n",
    "|*|*|*|\n",
    "|-|-|-|\n",
    "| ![Apple-dog](https://emojipedia-us.s3.dualstack.us-west-1.amazonaws.com/thumbs/120/apple/225/dog-face_1f436.png) | ![Apple-cat](https://emojipedia-us.s3.dualstack.us-west-1.amazonaws.com/thumbs/120/apple/225/cat_1f408.png) | ![Apple-dog](https://emojipedia-us.s3.dualstack.us-west-1.amazonaws.com/thumbs/120/apple/225/dog-face_1f436.png) |\n",
    "| ![Apple-cat](https://emojipedia-us.s3.dualstack.us-west-1.amazonaws.com/thumbs/120/apple/225/cat_1f408.png) | ![Apple-dog](https://emojipedia-us.s3.dualstack.us-west-1.amazonaws.com/thumbs/120/apple/225/dog-face_1f436.png) | ![Apple-cat](https://emojipedia-us.s3.dualstack.us-west-1.amazonaws.com/thumbs/120/apple/225/cat_1f408.png) |\n",
    "| ![Apple-cat](https://emojipedia-us.s3.dualstack.us-west-1.amazonaws.com/thumbs/120/apple/225/cat_1f408.png) | ![Apple-dog](https://emojipedia-us.s3.dualstack.us-west-1.amazonaws.com/thumbs/120/apple/225/dog-face_1f436.png) | ![Apple-cat](https://emojipedia-us.s3.dualstack.us-west-1.amazonaws.com/thumbs/120/apple/225/cat_1f408.png) |\n",
    "\n",
    "Fig 2: Control Group in RCT (one square = 100k of that animal), assuming no selection bias. Dog='At Risk', Cat='Not At Risk'\n",
    "\n",
    "|*|*|*|\n",
    "|-|-|-|\n",
    "| ![Apple-dog](https://emojipedia-us.s3.dualstack.us-west-1.amazonaws.com/thumbs/120/apple/225/dog-face_1f436.png) | ![Apple-cat](https://emojipedia-us.s3.dualstack.us-west-1.amazonaws.com/thumbs/120/apple/225/cat_1f408.png) | ![Apple-dog](https://emojipedia-us.s3.dualstack.us-west-1.amazonaws.com/thumbs/120/apple/225/dog-face_1f436.png) |\n",
    "| ![Apple-cat](https://emojipedia-us.s3.dualstack.us-west-1.amazonaws.com/thumbs/120/apple/225/cat_1f408.png) | ![Apple-dog](https://emojipedia-us.s3.dualstack.us-west-1.amazonaws.com/thumbs/120/apple/225/dog-face_1f436.png) | ![Apple-cat](https://emojipedia-us.s3.dualstack.us-west-1.amazonaws.com/thumbs/120/apple/225/cat_1f408.png) |\n",
    "| ![Apple-cat](https://emojipedia-us.s3.dualstack.us-west-1.amazonaws.com/thumbs/120/apple/225/cat_1f408.png) | ![Apple-dog](https://emojipedia-us.s3.dualstack.us-west-1.amazonaws.com/thumbs/120/apple/225/dog-face_1f436.png) | ![Apple-cat](https://emojipedia-us.s3.dualstack.us-west-1.amazonaws.com/thumbs/120/apple/225/cat_1f408.png) |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cons\n",
    "\n",
    "- Might be unethical / really expensive (e.g. assessing the effect of smoking on cancer in the 70s).\n",
    "\n",
    "| * |\n",
    "| - |\n",
    "| ![Image of lungs and a lit cigarette](http://a360-wp-uploads.s3.amazonaws.com/wp-content/uploads/rtmagazi/2015/09/dreamstime_xs_58648955-399x350.jpg) |\n",
    "\n",
    "- Still susceptible to Selection Bias.\n",
    "\n",
    "| Success Academy Alleged Bias | Corresponding Diagram |\n",
    "| - | - |\n",
    "| ![NYTimes: Filing Alleges Bias at Success Academy Network Against Students With Disabilities](./img/success-academy-bias.png) | ![Risk points to Transfer variable, which is adjusted for](./img/transfer-selection-bias.png) | \n",
    "\n",
    "Example: If Tutoring is randomized, but we only have access to data of students who *didn't* transfer, then our results could be biased.\n",
    "\n",
    "In other words, when analyzing the results of the randomized control trial, that gives us $P(G=1 \\mid do(T=1), Tr=0) - P(G=1 \\mid do(T=0), Tr=0)$, which could be different from our target quantity $P(G=1 \\mid do(T=1)) - P(G=1 \\mid do(T=0))$.\n",
    "\n",
    "- Questionable transportability: (e.g. RCT on mice. Would the results of that study be applicable to humans?)\n",
    "\n",
    "| Lab Mouse |\n",
    "| - |\n",
    "| ![Lab mouse](https://speakingofresearch.files.wordpress.com/2018/04/mouse-cv.jpg?w=863) |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To address the shortcomings of RCTs, today we will learn some causal graph theory!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chains\n",
    "\n",
    "| An example of a a chain |\n",
    "| - |\n",
    "| ![Middle School -> High School -> College](./img/mid-high-college.png) |\n",
    "\n",
    "Let $c$ stand for some value of `Graduate College`, $h$ stand for some value of `Graduate High School`, and $m$ stand for some value of `Graduate Middle School`.\n",
    "\n",
    "The left node and the right node are associated, i.e. the path from $\\text{Graduate Middle School} \\rightarrow \\text{Graduate High School} \\rightarrow \\text{Graduate College}$ is open. However, if we condition on the middle node $\\text{Graduate High School}$ (i.e. if we know someone graduated or did not graduate, then the other nodes are no longer associated. Doing so *blocks* the path $\\text{Graduate Middle School} \\rightarrow \\text{Graduate High School} \\rightarrow \\text{Graduate College}$.\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{aligned}\n",
    "    P(c) &\\neq P(c \\mid m) &\\text{$m$ tells us something about $c$} \\\\\n",
    "    P(m) &\\neq P(m \\mid c) &\\text{$c$ tells us something about $m$} \\\\\n",
    "    P(c \\mid h ) &= P(c \\mid h, m) & \\text{Once we know h, $m$ tells us nothing about $c$.} \\\\\n",
    "    P(m \\mid h ) &= P(m \\mid h, c) & \\text{Once we know h, $c$ tells us nothing about $m$.} \\\\ \n",
    "\\end{aligned}\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{aligned}\n",
    "    C &\\perp \\!\\!\\! \\perp  M \\mid H & \\text{$C$ is independent of $M$ given $H$}\n",
    "\\end{aligned}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forks\n",
    "\n",
    "| An example of a fork |\n",
    "| - |\n",
    "| ![Age causes intelligence and shoe size](./img/age-intel-shoe-size.png) |\n",
    "\n",
    "Let $i$ stand for some value of `Intelligence`, $a$ for some value of `Age`, and $s$ for some value of `Shoe Size`.\n",
    "\n",
    "Just like in the chain example, the non-middle-nodes are associated until we know the value of the middle node. The path $\\text{Intelligence} \\leftarrow \\text{Age} \\rightarrow \\text{Shoe Size}$ is *open* and transmits information. However, if we know the `Age`, then `Intelligence` tells us nothing about `Shoe Size` and vice versa. In other words, conditioning on `Age` blocks the path $\\text{Intelligence} \\leftarrow \\text{Age} \\rightarrow \\text{Shoe Size}$.\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{aligned}\n",
    "    P(i) &\\neq P(i \\mid s) & \\text{$s$ tells us something about $i$.} \\\\\n",
    "    P(s) &\\neq P(s \\mid i) & \\text{$i$ tells us something about $s$.} \\\\\n",
    "    P(i \\mid a) &= P(i \\mid a, s) & \\text{Once we know $a$, $s$ tells us nothing about $i$.} \\\\\n",
    "    P(s \\mid a) &= P(s \\mid a, i) & \\text{Once we know $a$, $i$ tells us nothing about $s$.} \\\\\n",
    "\\end{aligned}\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{aligned}\n",
    "    I &\\perp \\!\\!\\! \\perp S \\mid A & \\text{$I$ is independent of $S$ given $A$.}\n",
    "\\end{aligned}\n",
    "\\end{equation}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Colliders\n",
    "\n",
    "| An example of a collider |\n",
    "| - |\n",
    "| ![SAT causes college scholarship, Musical skill also causes college scholarship](./img/sat-scholarship-musical.png) |\n",
    "\n",
    "Let $s$ stand for some value of `SAT score`, $m$ for some value of `Musical Skill` , and $c$ for some value of `College Scholarship`.\n",
    "\n",
    "`Musical Skill` is independent of `SAT score` in the general population. In other words, the path $\\text{SAT score} \\rightarrow \\text{College Scholarship} \\leftarrow \\text{Musical Skill}$ is blocked if we don't know the value of `College Scholarship`. However, if we know that someone has a college scholarship and they have low `Musical Skill`, then they are more likely to have a high `SAT score`. In other words, conditioning on the value of `College Scholarship` opens the path $\\text{SAT score} \\rightarrow \\text{College Scholarship} \\leftarrow \\text{Musical Skill}$.\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{aligned}\n",
    "    P(s) &= P(s \\mid m) & \\text{$m$ tells me nothing about $s$, if we don't know about $c$.}\\\\\n",
    "    P(m) &= P(m \\mid s) & \\text{$s$ tells me nothing about $m$, if we don't know about $c$.} \\\\\n",
    "    P(s) &\\neq P(s \\mid m, c) &\\text{Once we know about $c$, and $m$, then that tells us something about $s$.}\\\\\n",
    "    P(m) &\\neq P(m \\mid s, c) & \\text{Once we know about $c$, and $s$, then that tells us something about $m$.} \\\\\n",
    "\\end{aligned}\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{aligned}\n",
    "    S &\\perp\\!\\!\\!\\perp M &\\text{$S$ and $M$ are marginally independent} \\\\\n",
    "    S & {\\not\\!\\perp\\!\\!\\!\\perp} M \\mid C &\\text{$S$ tells us about $M$, and vice versa, once we know $C$.}\n",
    "\\end{aligned}\n",
    "\\end{equation}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descendants of Colliders\n",
    "\n",
    "| Student Debt is a descendant of a collider | \n",
    "| - |\n",
    "| <img alt=\"Student Debt listens to College Scholarship\" src=\"./img/desc-collider.png\" width=500> |\n",
    "\n",
    "Let $s$ stand for some value of `SAT score`, $m$ for some value of `Musical Skill`, $c$ for some value of `College Scholarship`, and $d$ for some value of `Student Debt`.\n",
    "\n",
    "Again, like in the collider example above `SAT score` and `Musical Skill` are independent of each other in the general population. However, if we know the value of the descendant of a collider, `Student Debt in the first month of freshman year` then `SAT score` and `Musical Skill` become dependent. In other words, conditioning on a descendant of a collider opens the path $\\text{SAT score} \\rightarrow \\text{College Scholarship} \\leftarrow \\text{Musical Skill}$.\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{aligned}\n",
    "    P(s) &= P(s \\mid m) & \\text{$m$ tells me nothing about $s$, if we don't know about $c$.}\\\\\n",
    "    P(m) &= P(m \\mid s) & \\text{$s$ tells me nothing about $m$, if we don't know about $c$.} \\\\\n",
    "    P(s) &\\neq P(s \\mid m, d) &\\text{Once we know about $d$, then knowing $m$ tells us something about $s$.}\\\\\n",
    "    P(m) &\\neq P(m \\mid s, d) & \\text{Once we know about $d$, then knowing $s$ tells us something about $m$.} \\\\\n",
    "\\end{aligned}\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{aligned}\n",
    "    S &\\perp\\!\\!\\!\\perp M &\\text{$S$ and $M$ are marginally independent} \\\\\n",
    "    S & {\\not\\!\\perp\\!\\!\\!\\perp} M \\mid D &\\text{$S$ tells us about $M$, and vice versa, once we know $D$.}\n",
    "\\end{aligned}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backdoor Criterion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $do$-calculus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Front-door Criterion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complex Arbitrary DAG with Unmeasured Variables Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mediation & Direct Effects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transportability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resources\n",
    "\n",
    "\n",
    "| Image | Notes | Link |\n",
    "| - | - | - |\n",
    "| <img src='https://prodimage.images-bn.com/pimages/9781541698963_p0_v1_s600x595.jpg' alt='Book of Why: The New Science of Cause & Effect cover' width=500> | An introduction meant for the more general public. It still is technical, has some math, but focuses more on stories and anecdotes instead of derivations. | [Book of Why: The New Science of Cause & Effect](https://www.amazon.com/Book-Why-Science-Cause-Effect/dp/046509760X) | \n",
    "| <img alt='Causal Inference in Statistics: A Primer' src='https://s3.amazonaws.com/vh-woo-images/causal-inference-in-statistics-a-primer-1st-edition.jpg' width=500> | Recommended by Pearl to be read after the Book of Why. Dives more into the math. Has end-of-chapter exercises. *Note: I have the solutions manual! I told Pearl I was self-studying and he graciously gave me a copy!* | [Causal Inference in Statistics: A Primer](https://www.amazon.com/Causal-Inference-Statistics-Judea-Pearl/dp/1119186846) |\n",
    "| <img src='https://images-na.ssl-images-amazon.com/images/I/511aGcbGLyL._SX343_BO1,204,203,200_.jpg' alt='Causality' width=500> | Goes more in-depth than the Primer book. | [Causality](https://www.amazon.com/Causality-Reasoning-Inference-Judea-Pearl/dp/052189560X) |\n",
    "| <img alt='Causal Inference: The Mixtape' src='https://i.gr-assets.com/images/S/compressed.photo.goodreads.com/books/1566276665i/47867837._UY630_SR1200,630_.jpg' width=500> | Has a section on DAGs, but focused more on causal inference techniques that are more commonly being used in Economics. *FREELY AVAILABLE*. | [Causal Inference: The Mixtape](https://www.scunning.com/mixtape.html) |\n",
    "| <img alt='Causal Diagrams: Draw your Assumptions Before Conclusions' src='./img/causal-diagrams-draw-your-assumptions.png' width=500> | *FREE* course on EDX. Makes use of Epidemiological case studies to serve as context as to why drawing your assumptions is important.  | [Causal Diagrams: Draw your Assumptions Before Conclusions](https://online-learning.harvard.edu/course/causal-diagrams-draw-your-assumptions-your-conclusions) |\n",
    "| not applicable | \"Causal Inference: What If\" is a book that dives into Hernan & Robins' Potential Outcomes with DAGs approach. *FREE*. | [Causal Inference: What if](https://www.hsph.harvard.edu/miguel-hernan/causal-inference-book/) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
