{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Causal Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why Study Causal Inference? \n",
    "- What are some mistakes that could happen if we do a naive analysis?\n",
    "  - Confounding example\n",
    "  - The definition of the do-operator\n",
    "\n",
    "RCTs\n",
    "    To find causal effects, one could randomize the treatment assignment. \n",
    "\n",
    "Chain\n",
    "\n",
    "Fork\n",
    "\n",
    "Collider\n",
    "\n",
    "Descendant of a collider\n",
    "\n",
    "\n",
    "\n",
    "Backdoor Criterion - \n",
    "  - When is seeing = doing?\n",
    "  - assumes you know the structure of the problem well enough\n",
    "  \n",
    "do-calculus\n",
    "\n",
    "Frontdoor Criterion\n",
    "  - lets us deal with partial knowledge of the graph / unmeasured variables\n",
    "  \n",
    "Crazy example\n",
    "\n",
    "Transportability\n",
    "\n",
    "Resources\n",
    "\n",
    "Book Club"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothetical Scenario"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to improve students' graduation rates. Let's say we have some treatment T and we're trying to analyze the efficacy of treatment T. We find that on average, the graduation rates of those who get treatment T are 26 percentage points worse than those who didn't get treatment T. In other words,\n",
    "\\begin{equation}\n",
    "\\begin{aligned}\n",
    "    P(G=1 \\mid T=1) - P(G=0 \\mid T=0) \\approx -26\\%\n",
    "\\end{aligned}\n",
    "\\end{equation}\n",
    "\n",
    "### Question:\n",
    "Should we recommend treatment T to students?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer:\n",
    "\n",
    "It depends on the data-generating mechanism!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation Does Not Necessarily Imply Causation\n",
    "Here's an example where looking at associations naively leads to the wrong conclusion. \n",
    "\n",
    "Treatment is negatively associated with graduation rate, even though the treatment is actually beneficial, on average!\n",
    "\n",
    "How could that be? Let's say in a hypothetical world, there are only three variables that matter: treatment $T$, graduation rate $G$. Students classified as \"at-risk\" $R$ are more likely to be sent to receive tutoring. At-risk students by definition are less likely to graduate. In other words, $R$ is a common cause of $T$ and $G$. Another way to say that is $T$ and $G$ are **confounded** by $R$. So if there's a lot of people at-risk who receive treatment, then it is quite possible that there is a negative association between the treatment and outcome, *even though the treatment actually improves the outcomes for most/all individuals*.\n",
    "\n",
    "![Risk is a common cause of treatment and graduation](./img/risk-tutoring-graduate.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confounding Example Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def risk(sample_size=10000):\n",
    "    \"\"\"\n",
    "      We generate two types of people: High risk vs. Low-risk people. \n",
    "      Risk, for example, could be in relation to dropping out of high school.\n",
    "    \"\"\"\n",
    "    \n",
    "    return np.random.binomial(n=1, p=0.3, size=sample_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tutoring(riskiness, proba_tutor_given_not_risky=0.1, proba_tutor_given_risky=0.9):\n",
    "    \"\"\"\n",
    "        Non-risky people (riskiness == 0) have a 10% chance of receiving a tutoring.\n",
    "        However, risky people have a 90% chance of receiving the tutoring.\n",
    "    \"\"\"\n",
    "    \n",
    "    probability_of_receiving_tutoring = \\\n",
    "        (riskiness == 0) * proba_tutor_given_not_risky + \\\n",
    "        (riskiness == 1) * proba_tutor_given_risky\n",
    "    \n",
    "    return np.random.binomial(n=1, p=probability_of_receiving_tutoring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graduate(riskiness, tutored):\n",
    "    \"\"\"\n",
    "        If risky and tutoring, graduation rate = 0.3\n",
    "        If risky and not tutoring, graduation rate = 0.2\n",
    "        If not-risky and tutoring, graduation rate = 0.9\n",
    "        If not-risky and not tutoring, graduation rate = 0.8\n",
    "        \n",
    "        Notice that tutoring increases graduation rates by 10 percentage points.\n",
    "    \"\"\"\n",
    "    \n",
    "    risky_and_tutored_grad_rate = 0.3\n",
    "    risky_and_not_tutored_grad_rate = 0.2\n",
    "    not_risky_and_tutored_grad_rate = 0.9\n",
    "    not_risky_and_not_tutored_grad_rate = 0.8\n",
    "    \n",
    "    graduation_probas = (riskiness == 1) * (tutored == 1) * risky_and_tutored_grad_rate + \\\n",
    "        (riskiness == 1) * (tutored == 0) * risky_and_not_tutored_grad_rate + \\\n",
    "        (riskiness == 0) * (tutored == 1) * not_risky_and_tutored_grad_rate + \\\n",
    "        (riskiness == 0) * (tutored == 0) * not_risky_and_not_tutored_grad_rate\n",
    "    \n",
    "    return np.random.binomial(n=1, p=graduation_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "riskiness = risk(sample_size)\n",
    "tutored = drug(riskiness)\n",
    "graduated = graduate(riskiness, tutored)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    'risk': riskiness,\n",
    "    'tutored': tutored,\n",
    "    'graduated': graduated\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Associated Risk Difference: $P(G=1 \\mid T=1) - P(G=0 \\mid T=0) \\approx -26\\%$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.26"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(\n",
    "    df[df['tutored'] == 1].graduated.mean() - df[df['tutored'] == 0].graduated.mean(),\n",
    "    2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, if we do a randomized control trial (i.e. we randomize the assignment of the treatment), we see that the treatment actually improves the outcomes by 10%, on average!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ri\n",
    "treated_sample = risk(sample_size)\n",
    "untreated_sample = risk(sample_size)\n",
    "\n",
    "round(\n",
    "    graduate(treated_sample, tutored=1).mean() - graduate(untreated_sample, tutored=0).mean(),\n",
    "    2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Causal Risk Difference: $P(G=1 \\mid do(T=1)) - P(G=0 \\mid do(T=0)) = 10\\%$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we were to only look at the associated risk difference (i.e. make a comparison of graduation rates of those who got treated vs. those who didn't get treated), we would erroneously conclude that the treatment, on average, is bad (i.e. decreases graduation rate by 26%), **but in actuality, it boosts graduation rate, on average, by 10 percentage points!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Randomized Control Trials (A/B Testing)\n",
    "\n",
    "\n",
    "Pros:\n",
    "- The only thing that's different between the treatment group and the control group is the presence or lack of treatment. Therefore, the difference in outcomes between the two could be attributed to the treatment!\n",
    "- Good [*internal validity*](https://en.wikipedia.org/wiki/Internal_validity).\n",
    "- Easy to understand, easy to interpret.\n",
    "\n",
    "Fig 1: Treatment Group in RCT (one square = 100k of that animal)\n",
    "\n",
    "|*|*|*|\n",
    "|-|-|-|\n",
    "| ![Apple-dog](https://emojipedia-us.s3.dualstack.us-west-1.amazonaws.com/thumbs/120/apple/225/dog-face_1f436.png) | ![Apple-cat](https://emojipedia-us.s3.dualstack.us-west-1.amazonaws.com/thumbs/120/apple/225/cat_1f408.png) | ![Apple-dog](https://emojipedia-us.s3.dualstack.us-west-1.amazonaws.com/thumbs/120/apple/225/dog-face_1f436.png) |\n",
    "| ![Apple-cat](https://emojipedia-us.s3.dualstack.us-west-1.amazonaws.com/thumbs/120/apple/225/cat_1f408.png) | ![Apple-dog](https://emojipedia-us.s3.dualstack.us-west-1.amazonaws.com/thumbs/120/apple/225/dog-face_1f436.png) | ![Apple-cat](https://emojipedia-us.s3.dualstack.us-west-1.amazonaws.com/thumbs/120/apple/225/cat_1f408.png) |\n",
    "| ![Apple-cat](https://emojipedia-us.s3.dualstack.us-west-1.amazonaws.com/thumbs/120/apple/225/cat_1f408.png) | ![Apple-dog](https://emojipedia-us.s3.dualstack.us-west-1.amazonaws.com/thumbs/120/apple/225/dog-face_1f436.png) | ![Apple-cat](https://emojipedia-us.s3.dualstack.us-west-1.amazonaws.com/thumbs/120/apple/225/cat_1f408.png) |\n",
    "\n",
    "Fig 2: Control Group in RCT (one square = 100k of that animal)\n",
    "\n",
    "|*|*|*|\n",
    "|-|-|-|\n",
    "| ![Apple-dog](https://emojipedia-us.s3.dualstack.us-west-1.amazonaws.com/thumbs/120/apple/225/dog-face_1f436.png) | ![Apple-cat](https://emojipedia-us.s3.dualstack.us-west-1.amazonaws.com/thumbs/120/apple/225/cat_1f408.png) | ![Apple-dog](https://emojipedia-us.s3.dualstack.us-west-1.amazonaws.com/thumbs/120/apple/225/dog-face_1f436.png) |\n",
    "| ![Apple-cat](https://emojipedia-us.s3.dualstack.us-west-1.amazonaws.com/thumbs/120/apple/225/cat_1f408.png) | ![Apple-dog](https://emojipedia-us.s3.dualstack.us-west-1.amazonaws.com/thumbs/120/apple/225/dog-face_1f436.png) | ![Apple-cat](https://emojipedia-us.s3.dualstack.us-west-1.amazonaws.com/thumbs/120/apple/225/cat_1f408.png) |\n",
    "| ![Apple-cat](https://emojipedia-us.s3.dualstack.us-west-1.amazonaws.com/thumbs/120/apple/225/cat_1f408.png) | ![Apple-dog](https://emojipedia-us.s3.dualstack.us-west-1.amazonaws.com/thumbs/120/apple/225/dog-face_1f436.png) | ![Apple-cat](https://emojipedia-us.s3.dualstack.us-west-1.amazonaws.com/thumbs/120/apple/225/cat_1f408.png) |\n",
    "\n",
    "\n",
    "Cons: \n",
    "\n",
    "- Might be unethical / really expensive.\n",
    "- Still susceptible to Selection Bias.\n",
    "- Questionable transportability: (e.g. RCT on mice. Would the results of that study be applicable to humans?)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confounding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Colliders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descendants of Colliders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backdoor Criterion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $do$-calculus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Front-door Criterion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complex Arbitrary DAG with Unmeasured Variables Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mediation & Direct Effects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transportability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resources\n",
    "\n",
    "\n",
    "| Image | Notes | Link |\n",
    "| - | - | - |\n",
    "| <img src='https://prodimage.images-bn.com/pimages/9781541698963_p0_v1_s600x595.jpg' alt='Book of Why: The New Science of Cause & Effect cover' width=500> | An introduction meant for the more general public. It still is technical, has some math, but focuses more on stories and anecdotes instead of derivations. | [Book of Why: The New Science of Cause & Effect](https://www.amazon.com/Book-Why-Science-Cause-Effect/dp/046509760X) | \n",
    "| <img alt='Causal Inference in Statistics: A Primer' src='https://s3.amazonaws.com/vh-woo-images/causal-inference-in-statistics-a-primer-1st-edition.jpg' width=500> | Recommended by Pearl to be read after the Book of Why. Dives more into the math. Has end-of-chapter exercises. *Note: I have the solutions manual! I told Pearl I was self-studying and he graciously gave me a copy!* | [Causal Inference in Statistics: A Primer](https://www.amazon.com/Causal-Inference-Statistics-Judea-Pearl/dp/1119186846) |\n",
    "| <img src='https://images-na.ssl-images-amazon.com/images/I/511aGcbGLyL._SX343_BO1,204,203,200_.jpg' alt='Causality' width=500> | Goes more in-depth than the Primer book. | [Causality](https://www.amazon.com/Causality-Reasoning-Inference-Judea-Pearl/dp/052189560X) |\n",
    "| <img alt='Causal Inference: The Mixtape' src='https://i.gr-assets.com/images/S/compressed.photo.goodreads.com/books/1566276665i/47867837._UY630_SR1200,630_.jpg' width=500> | Has a section on DAGs, but focused more on causal inference techniques that are more commonly being used in Economics. *FREELY AVAILABLE*. | [Causal Inference: The Mixtape](https://www.scunning.com/mixtape.html) |\n",
    "| <img alt='Causal Diagrams: Draw your Assumptions Before Conclusions' src='./img/causal-diagrams-draw-your-assumptions.png' width=500> | *FREE* course on EDX. Makes use of Epidemiological case studies to serve as context as to why drawing your assumptions is important.  | [Causal Diagrams: Draw your Assumptions Before Conclusions](https://online-learning.harvard.edu/course/causal-diagrams-draw-your-assumptions-your-conclusions) |\n",
    "| not applicable | \"Causal Inference: What If\" is a book that dives into Hernan & Robins' Potential Outcomes with DAGs approach. *FREE*. | [Causal Inference: What if](https://www.hsph.harvard.edu/miguel-hernan/causal-inference-book/) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
